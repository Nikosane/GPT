Bad actors, including authoritarian governments, terrorists, criminals, and rogue states, find utility in the plethora of tools provided by artificial intelligence. One alarming manifestation is the lethal autonomous weapon, capable of identifying, selecting, and engaging human targets sans human intervention. The accessibility of AI tools facilitates the development of inexpensive autonomous weapons by malevolent entities, potentially culminating in weapons of mass destruction if produced on a large scale. Even in conventional warfare scenarios, their unreliability in target selection poses the risk of innocent casualties. Despite calls for a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, discord persists among nations, with some like China supporting the ban while others like the United States dissent. The proliferation of AI tools also empowers authoritarian regimes in various oppressive tactics. Widespread surveillance facilitated by face and voice recognition aids in citizen control, with machine learning enabling the identification and suppression of perceived threats to the state. Recommendation systems efficiently disseminate propaganda and misinformation, while technologies like deepfakes and generative AI further blur the lines between truth and fiction. Moreover, advanced AI enhances centralized decision-making in authoritarian systems, rivaling the efficiency of liberal and decentralized models such as markets. The digital landscape witnesses a lowering of barriers to entry in warfare and espionage, with AI-driven advancements making these endeavors more accessible and cost-effective. Notably, AI facial recognition systems have already been deployed for mass surveillance in China, showcasing the rapid integration of such technologies into oppressive regimes. Furthermore, the scope of AI's potential assistance to bad actors extends beyond current understanding, with machine-learning AI capable of designing toxic molecules en masse within mere hours. However, the development and training of AI systems necessitate significant computing power, a resource predominantly accessible to industry giants. Thus, smaller entities like startups often resort to purchasing access to data centers from tech behemoths like Google and Microsoft to engage in AI development endeavors.
Economists have frequently raised concerns about the potential for technological unemployment resulting from advances in AI, highlighting the need for robust social policies to ensure full employment. While historical trends have seen technology augmenting total employment, the emergence of AI presents uncharted territory according to economists. There's disagreement among economists regarding the extent to which increased use of robots and AI might lead to long-term unemployment, with varying risk estimates. For instance, some estimates suggest a substantial portion of U.S. jobs are at "high risk" of automation, while others indicate a much lower percentage. Criticism has been directed towards methodologies that speculate on future employment levels, questioning their evidential basis and suggesting a focus on social policy rather than attributing unemployment solely to technology. Recent reports highlight the swift impact of AI on certain industries, such as the elimination of 70% of jobs for Chinese video game illustrators by generative artificial intelligence. Unlike previous waves of automation, AI poses a threat to many middle-class jobs, with concerns likening its impact to that of steam power during the Industrial Revolution. Roles ranging from paralegals to fast food cooks face heightened risk, while demand is expected to rise for care-related professions. Since the early stages of AI development, ethical debates have emerged regarding whether tasks suitable for computers align with human capabilities and values, echoing concerns raised by figures like Joseph Weizenbaum.
